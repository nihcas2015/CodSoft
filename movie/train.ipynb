{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9933db4d",
   "metadata": {},
   "source": [
    "# Movie Genre Classification with BERT on Kaggle T4\n",
    "\n",
    "This notebook implements movie genre classification using BERT transformer model, optimized for Kaggle T4 GPU environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76baae73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:09:45.414545Z",
     "iopub.status.busy": "2025-06-29T13:09:45.414329Z",
     "iopub.status.idle": "2025-06-29T13:11:06.201755Z",
     "shell.execute_reply": "2025-06-29T13:11:06.200952Z",
     "shell.execute_reply.started": "2025-06-29T13:09:45.414522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCUDA available: True\n",
      "GPU device count: 2\n",
      "GPU device name: Tesla T4\n",
      "GPU memory: 14.74127197265625 GB\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies for Kaggle T4 environment\n",
    "!pip install transformers[torch] datasets tokenizers accelerate -q\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU memory:\", torch.cuda.get_device_properties(0).total_memory / 1024**3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82a2bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:11:06.203618Z",
     "iopub.status.busy": "2025-06-29T13:11:06.203320Z",
     "iopub.status.idle": "2025-06-29T13:11:32.490382Z",
     "shell.execute_reply": "2025-06-29T13:11:32.489615Z",
     "shell.execute_reply.started": "2025-06-29T13:11:06.203597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 13:11:18.814624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751202679.026521      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751202679.091202      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1169fa6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:01.431244Z",
     "iopub.status.busy": "2025-06-29T13:24:01.430523Z",
     "iopub.status.idle": "2025-06-29T13:24:01.977276Z",
     "shell.execute_reply": "2025-06-29T13:24:01.976632Z",
     "shell.execute_reply.started": "2025-06-29T13:24:01.431223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from: /kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\n"
     ]
    }
   ],
   "source": [
    "# Load training data (adjust path for Kaggle dataset)\n",
    "# For Kaggle: Upload dataset and use: \"/kaggle/input/your-dataset-name/train_data.txt\"\n",
    "train_file_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\"\n",
    "# Fallback for local testing\n",
    "\n",
    "print(f\"Loading training data from: {train_file_path}\")\n",
    "\n",
    "with open(train_file_path, \"r\", encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "target = []\n",
    "parts = []\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = lines[i].strip()\n",
    "    parts = lines[i].split(\":::\")\n",
    "      # Safety check\n",
    "    target.append(parts[2].strip())\n",
    "    lines[i] = parts[3].strip()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e25d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:08.983957Z",
     "iopub.status.busy": "2025-06-29T13:24:08.983480Z",
     "iopub.status.idle": "2025-06-29T13:24:09.012352Z",
     "shell.execute_reply": "2025-06-29T13:24:09.011879Z",
     "shell.execute_reply.started": "2025-06-29T13:24:08.983934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "y=le.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d98e2157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:12.026599Z",
     "iopub.status.busy": "2025-06-29T13:24:12.026046Z",
     "iopub.status.idle": "2025-06-29T13:24:12.039923Z",
     "shell.execute_reply": "2025-06-29T13:24:12.039217Z",
     "shell.execute_reply.started": "2025-06-29T13:24:12.026575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": lines,\n",
    "    \"label\": y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce78d07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:15.530619Z",
     "iopub.status.busy": "2025-06-29T13:24:15.530144Z",
     "iopub.status.idle": "2025-06-29T13:24:15.885362Z",
     "shell.execute_reply": "2025-06-29T13:24:15.884825Z",
     "shell.execute_reply.started": "2025-06-29T13:24:15.530597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78b0d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:24.301114Z",
     "iopub.status.busy": "2025-06-29T13:24:24.300825Z",
     "iopub.status.idle": "2025-06-29T13:24:25.023530Z",
     "shell.execute_reply": "2025-06-29T13:24:25.022623Z",
     "shell.execute_reply.started": "2025-06-29T13:24:24.301093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from: /kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\n",
      "Loaded 54200 test samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load test data (adjust path for Kaggle dataset)\n",
    "test_file_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\"\n",
    "test_solution_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data_solution.txt\"\n",
    "\n",
    "# Fallback for local testing\n",
    "\n",
    "print(f\"Loading test data from: {test_file_path}\")\n",
    "\n",
    "with open(test_file_path, \"r\", encoding='utf-8') as file:\n",
    "    test_lines = file.readlines()\n",
    "\n",
    "for i in range(len(test_lines)):\n",
    "    test_lines[i] = test_lines[i].strip()\n",
    "    parts = test_lines[i].split(\":::\")\n",
    "    if len(parts) >= 3:\n",
    "        test_lines[i] = parts[2].strip()\n",
    "\n",
    "with open(test_solution_path, \"r\", encoding='utf-8') as file:\n",
    "    test_target = file.readlines()\n",
    "\n",
    "test_target = [line.strip() for line in test_target]\n",
    "for i in range(len(test_target)):\n",
    "    parts = test_target[i].split(\":::\")\n",
    "    if len(parts) >= 3:\n",
    "        test_target[i] = parts[2].strip()\n",
    "\n",
    "y_test = le.transform(test_target)\n",
    "print(f\"Loaded {len(test_lines)} test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180107ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:28.511235Z",
     "iopub.status.busy": "2025-06-29T13:24:28.510957Z",
     "iopub.status.idle": "2025-06-29T13:24:28.527755Z",
     "shell.execute_reply": "2025-06-29T13:24:28.526991Z",
     "shell.execute_reply.started": "2025-06-29T13:24:28.511213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    \"text\": test_lines,\n",
    "    \"label\": y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2fda665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:31.009229Z",
     "iopub.status.busy": "2025-06-29T13:24:31.008977Z",
     "iopub.status.idle": "2025-06-29T13:24:31.272382Z",
     "shell.execute_reply": "2025-06-29T13:24:31.271837Z",
     "shell.execute_reply.started": "2025-06-29T13:24:31.009211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581c730b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:35.009253Z",
     "iopub.status.busy": "2025-06-29T13:24:35.008930Z",
     "iopub.status.idle": "2025-06-29T13:24:35.789856Z",
     "shell.execute_reply": "2025-06-29T13:24:35.789256Z",
     "shell.execute_reply.started": "2025-06-29T13:24:35.009227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f39484d4ed4671a20084c9cc00ee02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680165e6f5fb4154a74cc3b59112910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c3147d7efe4b5898c0b0afc98d36bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625448e67ccf41bdb01f3d1fdf73d6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "069df356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:24:39.894044Z",
     "iopub.status.busy": "2025-06-29T13:24:39.893775Z",
     "iopub.status.idle": "2025-06-29T13:28:01.865933Z",
     "shell.execute_reply": "2025-06-29T13:28:01.865187Z",
     "shell.execute_reply.started": "2025-06-29T13:24:39.894024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a33019af8074b988322e65e831c4b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79a10539d1147a3bc33f85b39e6297f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a92776b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:28:01.867562Z",
     "iopub.status.busy": "2025-06-29T13:28:01.867319Z",
     "iopub.status.idle": "2025-06-29T13:28:04.043994Z",
     "shell.execute_reply": "2025-06-29T13:28:04.043410Z",
     "shell.execute_reply.started": "2025-06-29T13:28:01.867546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1153d0d66d41c285fbe5b00454206c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21afb329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:56:24.945509Z",
     "iopub.status.busy": "2025-06-29T13:56:24.945234Z",
     "iopub.status.idle": "2025-06-29T13:56:24.994495Z",
     "shell.execute_reply": "2025-06-29T13:56:24.993601Z",
     "shell.execute_reply.started": "2025-06-29T13:56:24.945488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optimized training arguments for Kaggle T4 GPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=16,  # Increased for T4\n",
    "    per_device_eval_batch_size=32,   # Larger for evaluation\n",
    "    num_train_epochs=3,              # Reduced for Kaggle time limits\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,                       # Enable mixed precision for T4\n",
    "    dataloader_num_workers=2,        # Optimize for Kaggle\n",
    "    save_total_limit=2,              # Save space\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "020a7c95-3219-455b-9793-f029dad09c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:36:57.051055Z",
     "iopub.status.busy": "2025-06-29T13:36:57.050345Z",
     "iopub.status.idle": "2025-06-29T13:36:57.055439Z",
     "shell.execute_reply": "2025-06-29T13:36:57.054612Z",
     "shell.execute_reply.started": "2025-06-29T13:36:57.051031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c03b150f-d072-4355-b8f1-f6e904b84098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T14:47:45.903008Z",
     "iopub.status.busy": "2025-06-29T14:47:45.902474Z",
     "iopub.status.idle": "2025-06-29T14:48:41.487247Z",
     "shell.execute_reply": "2025-06-29T14:48:41.486538Z",
     "shell.execute_reply.started": "2025-06-29T14:47:45.902984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a19fca0-99d0-40ef-be44-c3e52038a8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T14:48:54.286150Z",
     "iopub.status.busy": "2025-06-29T14:48:54.285844Z",
     "iopub.status.idle": "2025-06-29T14:49:00.635256Z",
     "shell.execute_reply": "2025-06-29T14:49:00.634576Z",
     "shell.execute_reply.started": "2025-06-29T14:48:54.286128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnihcas2015\u001b[0m (\u001b[33mnihcas2015-vellore-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250629_144854-3i89a318</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification/runs/3i89a318' target=\"_blank\">bert-run-1</a></strong> to <a href='https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification' target=\"_blank\">https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification/runs/3i89a318' target=\"_blank\">https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification/runs/3i89a318</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nihcas2015-vellore-institute-of-technology/bert-genre-classification/runs/3i89a318?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7916da611a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"ab11e1d1e666be11c522a1a2a04dcb2acd82bd07\")\n",
    "\n",
    "wandb.init(project=\"bert-genre-classification\", name=\"bert-run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "824d4330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T14:49:07.188605Z",
     "iopub.status.busy": "2025-06-29T14:49:07.188320Z",
     "iopub.status.idle": "2025-06-29T16:06:16.999646Z",
     "shell.execute_reply": "2025-06-29T16:06:16.998745Z",
     "shell.execute_reply.started": "2025-06-29T14:49:07.188583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5085' max='5085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5085/5085 1:09:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.940100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.663100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.546600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.389500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.268700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.239700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.240800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.204200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.211500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.969900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.961800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.880500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.985400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.806400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.748400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.789700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.765800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.714200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.768800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 1.098167061805725, 'eval_accuracy': 0.6771771217712177, 'eval_precision': 0.6579181211779688, 'eval_recall': 0.6771771217712177, 'eval_f1': 0.6600026787573379, 'eval_runtime': 450.9146, 'eval_samples_per_second': 120.2, 'eval_steps_per_second': 1.878, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5f35b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T13:56:14.908354Z",
     "iopub.status.busy": "2025-06-29T13:56:14.907998Z",
     "iopub.status.idle": "2025-06-29T13:56:15.117975Z",
     "shell.execute_reply": "2025-06-29T13:56:15.117183Z",
     "shell.execute_reply.started": "2025-06-29T13:56:14.908303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 2.16 GB\n",
      "GPU memory cached: 2.52 GB\n"
     ]
    }
   ],
   "source": [
    "# Memory optimization for Kaggle\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory cached: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f879954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T16:17:50.118859Z",
     "iopub.status.busy": "2025-06-29T16:17:50.118520Z",
     "iopub.status.idle": "2025-06-29T16:25:23.234250Z",
     "shell.execute_reply": "2025-06-29T16:25:23.233461Z",
     "shell.execute_reply.started": "2025-06-29T16:17:50.118834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./final_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved with 54200 predictions\n",
      "\n",
      "Final Model Performance:\n",
      "Test Accuracy: 0.6772\n",
      "Test F1-Score: 0.6600\n",
      "Test Precision: 0.6579\n",
      "Test Recall: 0.6772\n"
     ]
    }
   ],
   "source": [
    "# Save the model for Kaggle output\n",
    "trainer.save_model(\"./final_model\")\n",
    "tokenizer.save_pretrained(\"./final_model\")\n",
    "\n",
    "print(\"Model saved to ./final_model\")\n",
    "\n",
    "# Generate predictions for submission\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.predictions.argmax(-1)\n",
    "predicted_genres = le.inverse_transform(predicted_labels)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'test_id': range(len(predicted_genres)),\n",
    "    'predicted_genre': predicted_genres\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file saved with {len(predicted_genres)} predictions\")\n",
    "\n",
    "# Display final metrics\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"Test Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "print(f\"Test F1-Score: {eval_result['eval_f1']:.4f}\")\n",
    "print(f\"Test Precision: {eval_result['eval_precision']:.4f}\")\n",
    "print(f\"Test Recall: {eval_result['eval_recall']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1417162,
     "sourceId": 2347441,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "codsoft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
